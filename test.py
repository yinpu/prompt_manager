from prompt_manager import PromptManager

pm = PromptManager("./save")

# 1. ç›´æ¥é€šè¿‡è·¯å¾„è·å– / åˆ›å»º
p = pm.get_prompt("/demo/hello/j2")

# 2. æ–°å¢ä¸€ä¸ªç‰ˆæœ¬ (è‡ªåŠ¨ç”Ÿæˆç‰ˆæœ¬å·)
p.add_version(
    content="Hello {name}!",
    model_outputs={
        "gpt-4o": "Hi Alice ğŸ‘‹",
        "llama3": {"output": "Hello, Alice.", "meta": {"temp": 0.3}},
    },
    meta={"lang": "en"},
)

# 2.1 æ–°å¢ä¸€ä¸ªè‡ªå®šä¹‰ç‰ˆæœ¬å·çš„ç‰ˆæœ¬
p.add_version(
    content="ä½ å¥½ {name}ï¼",
    model_outputs={
        "gpt-4o": "ä½ å¥½ï¼Œçˆ±ä¸½ä¸ ğŸ‘‹",
    },
    meta={"lang": "zh"},
    version="chinese-v1",  # è‡ªå®šä¹‰ç‰ˆæœ¬å·
)
p.save()                # æŒä¹…åŒ–

# 3. ä¿®æ”¹å·²æœ‰ç‰ˆæœ¬
v1 = p.modify_version(
    "v0001",
    meta_update={"reviewed": True},
)
p.save(overwrite_existing=True)

# 3.1 å‘ç°æœ‰ç‰ˆæœ¬æ·»åŠ æ¨¡å‹è¾“å‡º
p.add_model_output(
    "chinese-v1",
    "claude-3",
    {"output": "ä½ å¥½ï¼Œçˆ±ä¸½ä¸ï¼å¾ˆé«˜å…´è§åˆ°ä½ ã€‚", "meta": {"temperature": 0.7}}
)
p.save(overwrite_existing=True)

# 3.2 é€‰æ‹©ç‰¹å®šç‰ˆæœ¬ä½œä¸ºå½“å‰ç‰ˆæœ¬
current_version = p.select_version("chinese-v1")
print(f"å½“å‰é€‰æ‹©çš„ç‰ˆæœ¬: {current_version.version}, è¯­è¨€: {current_version.meta.get('lang')}")

# 4. å¯¼å‡º
export_file = p.export("./hello_prompt.json")

# 5. å¯¼å…¥åˆ°å¦ä¸€é¡¹ç›® /prompt å
p2 = pm.import_prompt(export_file, "/newproj/hello_copy")
print(p2.latest.content)  # åº”è¯¥æ˜¯ "ä½ å¥½ {name}ï¼" å› ä¸ºæˆ‘ä»¬é€‰æ‹©äº† chinese-v1 ä½œä¸ºå½“å‰ç‰ˆæœ¬

# 6. è·å–æ‰€æœ‰ç‰ˆæœ¬å¹¶éå†
print("\næ‰€æœ‰å¯ç”¨ç‰ˆæœ¬:")
for version in p.versions:
    print(f"- {version.version}: {version.content[:20]}... ({len(version.model_outputs)} ä¸ªæ¨¡å‹è¾“å‡º)")